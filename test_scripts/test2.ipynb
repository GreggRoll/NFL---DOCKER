{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import sqlite3\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def setup_logger(name):\n",
    "    \"\"\"Set up a logger for a given module.\"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler('app.log')\n",
    "    formatter = logging.Formatter('%(asctime)s [%(levelname)s] - %(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "\n",
    "    # Add the handler to the logger\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(fh)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger(__name__)\n",
    "\n",
    "def insert_data_to_db(df, conn, table):\n",
    "    try:\n",
    "        df.to_sql(table, conn, if_exists='append', index=False)\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"SQL INSERT Error on TABLE: {table}\\n{e}\")\n",
    "\n",
    "def insert_bovada_data(current_df):\n",
    "    with sqlite3.connect('../data-log.db') as conn:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Initialize an empty list to collect DataFrames for concatenation\n",
    "        games_to_insert_list = []\n",
    "\n",
    "        # Iterate over each game in the current DataFrame\n",
    "        for index, game in current_df.iterrows():\n",
    "            game_id = game['game_id']\n",
    "\n",
    "            # Fetch the corresponding game data from the database by game_id\n",
    "            cursor.execute(\"SELECT * FROM bovada_data WHERE game_id = ?\", (game_id,))\n",
    "            db_game = cursor.fetchone()\n",
    "            columns = ['date', 'time', 'bets', 'home_team', 'away_team', 'home_win', 'away_win', 'win_differential', 'day', 'points', 'game_id']\n",
    "\n",
    "            if db_game:\n",
    "                # Convert db_game to DataFrame for comparison\n",
    "                db_game_df = pd.DataFrame([db_game], columns=columns)\n",
    "\n",
    "                # Prepare current game data for comparison\n",
    "                current_game_df = pd.DataFrame([game], columns=columns)\n",
    "                # current_game_df['datetime'] = datetime.now().isoformat()\n",
    "\n",
    "                # Compare with current game data\n",
    "                if not current_game_df.equals(db_game_df):\n",
    "                    # Add to the list for bulk insertion\n",
    "                    games_to_insert_list.append(current_game_df)\n",
    "            else:\n",
    "                # If there is no entry for this game in the database, prepare for insertion\n",
    "                # game['datetime'] = datetime.now().isoformat()\n",
    "                games_to_insert_list.append(pd.DataFrame([game], columns=columns))\n",
    "\n",
    "        # Concatenate all DataFrames in the list for bulk insertion\n",
    "        if games_to_insert_list:\n",
    "            games_to_insert = pd.concat(games_to_insert_list, ignore_index=True)\n",
    "            insert_data_to_db(games_to_insert, conn, 'bovada_data')\n",
    "        logger.info(\"Added bovada data to SQL\")\n",
    "\n",
    "\n",
    "def insert_matchup_data(current_df):\n",
    "    with sqlite3.connect('../data-log.db') as conn:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Initialize an empty list to collect DataFrames for concatenation\n",
    "        games_to_insert_list = []\n",
    "\n",
    "        # Iterate over each game in the current DataFrame\n",
    "        for index, game in current_df.iterrows():\n",
    "            game_id = game['game_id']\n",
    "\n",
    "            # Fetch the corresponding game data from the database by game_id\n",
    "            cursor.execute(\"SELECT * FROM matchup_data WHERE game_id = ?\", (game_id,))\n",
    "            db_game = cursor.fetchone()\n",
    "            columns = ['time', 'matchup', 'projected_winner', 'ranking', 'game_id']\n",
    "\n",
    "            if db_game:\n",
    "                # Convert db_game to DataFrame for comparison\n",
    "                db_game_df = pd.DataFrame([db_game], columns=columns)\n",
    "\n",
    "                # Prepare current game data for comparison\n",
    "                current_game_df = pd.DataFrame([game], columns=columns)\n",
    "                # current_game_df['datetime'] = datetime.now().isoformat()\n",
    "\n",
    "                # Compare with current game data\n",
    "                if not current_game_df.equals(db_game_df):\n",
    "                    # Add to the list for bulk insertion\n",
    "                    games_to_insert_list.append(current_game_df)\n",
    "            else:\n",
    "                # If there is no entry for this game in the database, prepare for insertion\n",
    "                # game['datetime'] = datetime.now().isoformat()\n",
    "                games_to_insert_list.append(pd.DataFrame([game], columns=columns))\n",
    "\n",
    "        # Concatenate all DataFrames in the list for bulk insertion\n",
    "        if games_to_insert_list:\n",
    "            games_to_insert = pd.concat(games_to_insert_list, ignore_index=True)\n",
    "            insert_data_to_db(games_to_insert, conn, 'matchup_data')\n",
    "        logger.info(\"Added matchup data to SQL\")\n",
    "\n",
    "def insert_expert_data(current_df):\n",
    "    with sqlite3.connect('../data-log.db') as conn:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Initialize an empty list to collect DataFrames for concatenation\n",
    "        games_to_insert_list = []\n",
    "\n",
    "        # Iterate over each game in the current DataFrame\n",
    "        for index, game in current_df.iterrows():\n",
    "            game_id = game['game_id']\n",
    "\n",
    "            # Fetch the corresponding game data from the database by game_id\n",
    "            cursor.execute(\"SELECT * FROM matchup_data WHERE game_id = ?\", (game_id,))\n",
    "            db_game = cursor.fetchone()\n",
    "\n",
    "            if db_game:\n",
    "                # Convert db_game to DataFrame for comparison\n",
    "                db_game_df = pd.DataFrame([db_game])\n",
    "\n",
    "                # Prepare current game data for comparison\n",
    "                current_game_df = pd.DataFrame([game])\n",
    "                current_game_df['datetime'] = datetime.now().isoformat()\n",
    "\n",
    "                # Compare with current game data\n",
    "                if not current_game_df.equals(db_game_df):\n",
    "                    # Add to the list for bulk insertion\n",
    "                    games_to_insert_list.append(current_game_df)\n",
    "            else:\n",
    "                # If there is no entry for this game in the database, prepare for insertion\n",
    "                game['datetime'] = datetime.now().isoformat()\n",
    "                games_to_insert_list.append(pd.DataFrame([game]))\n",
    "\n",
    "        # Concatenate all DataFrames in the list for bulk insertion\n",
    "        if games_to_insert_list:\n",
    "            games_to_insert = pd.concat(games_to_insert_list, ignore_index=True)\n",
    "            insert_data_to_db(games_to_insert, conn, 'expert_data')\n",
    "        logger.info(\"Added expert data to SQL\")\n",
    "\n",
    "def insert_merge_data(current_df):\n",
    "    with sqlite3.connect('../data-log.db') as conn:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Initialize an empty list to collect DataFrames for concatenation\n",
    "        games_to_insert_list = []\n",
    "\n",
    "        # Iterate over each game in the current DataFrame\n",
    "        for index, game in current_df.iterrows():\n",
    "            game_id = game['game_id']\n",
    "\n",
    "            # Fetch the corresponding game data from the database by game_id\n",
    "            cursor.execute(\"SELECT * FROM merged_data WHERE game_id = ?\", (game_id,))\n",
    "            db_game = cursor.fetchone()\n",
    "\n",
    "            if db_game:\n",
    "                # Convert db_game to DataFrame for comparison\n",
    "                db_game_df = pd.DataFrame([db_game])\n",
    "\n",
    "                # Prepare current game data for comparison\n",
    "                current_game_df = pd.DataFrame([game])\n",
    "\n",
    "                # Compare with current game data\n",
    "                if not current_game_df.equals(db_game_df):\n",
    "                    # Add to the list for bulk insertion\n",
    "                    games_to_insert_list.append(current_game_df)\n",
    "            else:\n",
    "                # If there is no entry for this game in the database, prepare for insertion\n",
    "                games_to_insert_list.append(pd.DataFrame([game]))\n",
    "\n",
    "        # Concatenate all DataFrames in the list for bulk insertion\n",
    "        if games_to_insert_list:\n",
    "            games_to_insert = pd.concat(games_to_insert_list, ignore_index=True)\n",
    "            insert_data_to_db(games_to_insert, conn, 'merged_data')\n",
    "        logger.info(\"Added MERGED data to SQL\")\n",
    "\n",
    "def generate_game_id(row):\n",
    "    try:\n",
    "        # Example: Use a combination of date, home team, and away team to generate a unique ID\n",
    "        identifier = f\"{row['date']}_{row['home_team']}_{row['away_team']}\"\n",
    "        return hashlib.md5(identifier.encode()).hexdigest()\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Generate Game error\")\n",
    "\n",
    "def convert_to_int(value):\n",
    "    try:\n",
    "        if value == 'EVEN':\n",
    "            return 0\n",
    "        if value.startswith('+'):\n",
    "            return int(value[1:])\n",
    "        elif value.startswith('-'):\n",
    "            return int(value)\n",
    "        else:\n",
    "            return int(value)\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Convert to int error\")\n",
    "        return -1\n",
    "\n",
    "def concat_values(x, y, z=None):\n",
    "    if z:\n",
    "        return f\"{x} {y} {z}\"\n",
    "    return f\"{x} {y}\"\n",
    "\n",
    "def get_data(start_date, end_date):\n",
    "    # Configure ChromeOptions for headless browsing\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")  # This line can be important in certain environments\n",
    "    options.set_capability('goog:loggingPrefs', {'browser': 'SEVERE'})\n",
    "    # Initialize the Chrome WebDriver with the specified options\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(\"https://www.bovada.lv/sports/football/nfl\")\n",
    "    # wait for the page to load\n",
    "    time.sleep(10)\n",
    "    driver.implicitly_wait(10)\n",
    "    # get the HTML source\n",
    "    html = driver.page_source\n",
    "    # create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    data = []\n",
    "    sections = soup.find_all(\"section\", {\"class\":\"coupon-content more-info\"})#soup.find_all(\"section\", {\"class\":\"coupon-content more-info\"})\n",
    "    for game in sections:\n",
    "        try:\n",
    "            item = str(game).split('>')\n",
    "            info = [x.split('<')[0].strip() for x in item if not x.startswith(\"<\")]\n",
    "            data.append(info)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    def get_bets(string):\n",
    "        try:\n",
    "            return int(string.split('+')[1].strip())\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    # df[\"Home Spread\"] = df.apply(lambda row: concat_values(row[10], row[11]), axis=1)\n",
    "    # df[\"Away Spread\"] = df.apply(lambda row: concat_values(row[12], row[13]), axis=1)\n",
    "    # df[\"total_home\"] = df.apply(lambda row: concat_values(row[16], row[17], row[18]), axis=1)\n",
    "    # df[\"total_away\"] = df.apply(lambda row: concat_values(row[19], row[20], row[21]), axis=1)\n",
    "    df['bets'] = df[2].apply(lambda x: get_bets(x))\n",
    "    df.rename(columns = {\n",
    "        0: \"date\",\n",
    "        1: \"time\",\n",
    "        6: \"home_team\",\n",
    "        7: \"away_team\",\n",
    "        14: \"home_win\",\n",
    "        15: \"away_win\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    df = df[[\"date\", \"time\", \"bets\", \"home_team\", \"away_team\", \"home_win\", \"away_win\"]]\n",
    "\n",
    "    def create_differential(home_win, away_win):\n",
    "        try:\n",
    "            home = int(home_win)\n",
    "            away = int(away_win)\n",
    "            return abs(home-away)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    df[\"win_differential\"] = df.apply(lambda row: create_differential(row['home_win'], row['away_win']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    #date operations\n",
    "    #filter data for date\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')  # Adjust the format if needed\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')  # Adjust the format if needed\n",
    "        # Ensure the 'date' column in df is of type datetime.date\n",
    "\n",
    "    # Ensure the 'date' column in df is of type datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    one_week_ago = pd.Timestamp(datetime.today().date() - timedelta(weeks=1))\n",
    "    df['date'].fillna(one_week_ago, inplace=True)\n",
    "\n",
    "    df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "    #create day of the week column\n",
    "    df[\"day\"] = df['date'].dt.strftime('%A')\n",
    "    #set back to string\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Applying the conversion to the 'win_home' and \"Away Win\" columns\n",
    "    df['home_win'] = df['home_win'].apply(convert_to_int)\n",
    "    df[\"away_win\"] = df[\"away_win\"].apply(convert_to_int)\n",
    "    #ranking\n",
    "    home = df[[\"home_team\", 'home_win']].rename(columns={'home_team': 'team', 'home_win': 'odds'})\n",
    "    away = df[['away_team', \"away_win\"]].rename(columns={'away_team': 'team', \"away_win\": 'odds'})\n",
    "    combined = pd.concat([home, away]).sort_values('odds', ascending=False)\n",
    "    combined['index'] = combined.index\n",
    "    combined.index = range(0, 2*len(combined), 2)\n",
    "    df['points'] = None\n",
    "    # Iterating over the combined DataFrame to assign ranks\n",
    "    for i, x in combined.iterrows():\n",
    "        df.at[x['index'], 'points'] = (i-len(combined))/2+1\n",
    "    current_df = df.sort_values('points', ascending=False)\n",
    "    #add game id\n",
    "    current_df[\"game_id\"] = current_df.apply(generate_game_id, axis=1)\n",
    "    insert_bovada_data(current_df)\n",
    "    return current_df\n",
    "\n",
    "def generate_matchups(df):\n",
    "    # Ensure DateTime is properly formatted\n",
    "    df['DateTime'] = pd.to_datetime(df['date']+' '+df['time'])\n",
    "\n",
    "    # Sort the DataFrame by DateTime to get matchups from soonest to latest\n",
    "    sorted_df = df.sort_values(by='DateTime')\n",
    "\n",
    "    # Prepare data for the DataTable\n",
    "    matchups_data = []\n",
    "\n",
    "    team_conversion_dict = {\n",
    "    \"Houston Texans\": \"HOU\",\n",
    "    \"New York Jets\": \"NYJ\",\n",
    "    \"Denver Broncos\": \"DEN\",\n",
    "    \"Baltimore Ravens\": \"BAL\",\n",
    "    \"Jacksonville Jaguars\": \"JAX\",\n",
    "    \"Philadelphia Eagles\": \"PHI\",\n",
    "    \"New Orleans Saints\": \"NO\",\n",
    "    \"Carolina Panthers\": \"CAR\",\n",
    "    \"Las Vegas Raiders\": \"LV\",\n",
    "    \"Cincinnati Bengals\": \"CIN\",\n",
    "    \"Miami Dolphins\": \"MIA\",\n",
    "    \"Buffalo Bills\": \"BUF\",\n",
    "    \"Indianapolis Colts\": \"IND\",\n",
    "    \"Minnesota Vikings\": \"MIN\",\n",
    "    \"Washington Commanders\": \"WSH\",\n",
    "    \"New York Giants\": \"NYG\",\n",
    "    \"Detroit Lions\": \"DET\",\n",
    "    \"Green Bay Packers\": \"GB\",\n",
    "    \"New England Patriots\": \"NE\",\n",
    "    \"Tennessee Titans\": \"TEN\",\n",
    "    \"Dallas Cowboys\": \"DAL\",\n",
    "    \"Atlanta Falcons\": \"ATL\",\n",
    "    \"Chicago Bears\": \"CHI\",\n",
    "    \"Arizona Cardinals\": \"ARI\",\n",
    "    \"Los Angeles Chargers\": \"LAC\",\n",
    "    \"Cleveland Browns\": \"CLE\",\n",
    "    \"Los Angeles Rams\": \"LAR\",\n",
    "    \"Seattle Seahawks\": \"SEA\",\n",
    "    \"Tampa Bay Buccaneers\": \"TB\",\n",
    "    \"Kansas City Chiefs\": \"KC\",\n",
    "    'San Francisco 49ers': \"SF\",\n",
    "    'Pittsburgh Steelers': \"PIT\"\n",
    "    }\n",
    "\n",
    "    for _, row in sorted_df.iterrows():\n",
    "        home_team = row['home_team']\n",
    "        away_team = row['away_team']\n",
    "        points = row['points']\n",
    "\n",
    "        # Determine the favored team\n",
    "        projected_winner = home_team if row['home_win'] < row['away_win'] else away_team\n",
    "\n",
    "        # Add row data\n",
    "        matchups_data.append({\n",
    "            \"game_id\": f\"{team_conversion_dict[home_team]}{team_conversion_dict[away_team]}\",\n",
    "            \"matchup\": f\"{home_team} vs {away_team}\",\n",
    "            \"time\": row['DateTime'].strftime('%A %H:%M %p'),\n",
    "            \"projected_winner\": projected_winner,\n",
    "            \"ranking\": points,\n",
    "            \"alt_game_id\": row['game_id']\n",
    "        })\n",
    "    matchup_df = pd.DataFrame(matchups_data).sort_values(\"ranking\", ascending=False)\n",
    "    # insert_matchup_data(matchup_df)\n",
    "    return matchup_df\n",
    "\n",
    "def get_espn_expert_data():\n",
    "    # Function to transform the game string\n",
    "    def transform_game(game):\n",
    "        try:\n",
    "            teams = game.split(' at ')\n",
    "            return teams[0] + teams[1]\n",
    "        except:\n",
    "            teams = game.split(' VS ')\n",
    "            return teams[0] + teams[1]\n",
    "    try:\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--disable-extensions\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "        options.add_argument(\"--no-sandbox\")  # This line can be important in certain environments\n",
    "        options.set_capability('goog:loggingPrefs', {'browser': 'SEVERE'})\n",
    "        # Initialize the Chrome WebDriver with the specified options\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(\"https://www.espn.com/nfl/picks\")\n",
    "        #time.sleep(10)\n",
    "        driver.implicitly_wait(10)\n",
    "        # get the HTML source\n",
    "        html = driver.page_source\n",
    "        # create a BeautifulSoup object\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # close the driver\n",
    "        driver.quit()\n",
    "\n",
    "        week = soup.find('h1', class_='headline headline__h1 dib').get_text(strip=True).split('- ')[1]\n",
    "\n",
    "        # Extract game details\n",
    "        games = []\n",
    "        game_rows = soup.select('.Table--fixed-left .Table__TBODY .Table__TR')\n",
    "        for row in game_rows:\n",
    "            game_info_element = row.select_one('.wrap-competition a')\n",
    "            game_time_element = row.select_one('.competition-dates')\n",
    "            if game_info_element and game_time_element:\n",
    "                game_info = game_info_element.text\n",
    "                game_time = game_time_element.text\n",
    "                games.append((game_info, game_time))\n",
    "\n",
    "        # Extract expert names\n",
    "        experts = []\n",
    "        expert_headers = soup.select('.Table__Scroller .Table__THEAD .Table__TH')\n",
    "        for header in expert_headers:\n",
    "            expert_name_element = header.select_one('div')\n",
    "            if expert_name_element:\n",
    "                expert_name = expert_name_element.text.strip()\n",
    "                experts.append(expert_name)\n",
    "\n",
    "        # Extract picks\n",
    "        picks = []\n",
    "        pick_rows = soup.select('.Table__Scroller .Table__TBODY .Table__TR')\n",
    "        for row in pick_rows:\n",
    "            pick_row = []\n",
    "            pick_cells = row.select('.Table__TD')\n",
    "            for cell in pick_cells:\n",
    "                team_logo = cell.select_one('img')\n",
    "                if team_logo:\n",
    "                    # Extract the team abbreviation from the image URL\n",
    "                    team = team_logo['src'].split('/')[-1].split('.')[0]\n",
    "                else:\n",
    "                    team = None\n",
    "                pick_row.append(team)\n",
    "            picks.append(pick_row)\n",
    "\n",
    "        # Create DataFrame\n",
    "        data = {'Game': [game[0] for game in games], 'Time': [game[1] for game in games]}\n",
    "        for i, expert in enumerate(experts):\n",
    "            data[expert] = [pick[i] for pick in picks]\n",
    "\n",
    "        data['Game'].append(None)\n",
    "        data['Time'].append(None)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.dropna(subset=[\"Game\"], inplace=True)\n",
    "\n",
    "        df['week'] = week\n",
    "\n",
    "        convert_dict = {\n",
    "            \"min\": \"Vikings\", \"phi\": \"Eagles\", \"bal\": \"Ravens\", \"det\": \"Lions\", \"mia\": \"Dolphins\",\n",
    "            \"nyj\": \"Jets\", \"atl\": \"Falcons\", \"gb\": \"Packers\", \"hou\" : \"Texans\", \"lac\": \"Chargers\",\n",
    "            \"buf\": \"Bills\", \"den\": \"Broncos\", \"kc\": \"Chiefs\", \"chi\": \"Bears\", \"sf\": \"49ers\", \"pit\": \"Steelers\",\n",
    "            \"no\": \"Saints\", \"cin\": \"Bengals\", \"ne\": \"Patriots\", \"wsh\": \"Commanders\", \"ari\": \"Cardinals\", \n",
    "            \"lar\": \"Rams\", \"tb\": \"Tampa Bay\", \"dal\": \"Dallas Cowboys\", \"ind\": \"Indianappolis Colts\", \n",
    "            \"sea\": \"Seattle Seahawks\"\n",
    "        }\n",
    "\n",
    "        for ix, row in df.iterrows():\n",
    "            values = row.to_list()[2:]\n",
    "            values = [value for value in values if value is not None]\n",
    "            values_len = len(values)\n",
    "            values_dict = {}\n",
    "            for value in values:\n",
    "                if value not in values_dict.keys():\n",
    "                    values_dict[value] = 1\n",
    "                else:\n",
    "                    values_dict[value] += 1\n",
    "            #sorting\n",
    "            values_dict = dict(sorted(values_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "            top_key = next(iter(values_dict))\n",
    "            if top_key in convert_dict:\n",
    "                converted_key = convert_dict[top_key]\n",
    "            else:\n",
    "                converted_key = top_key\n",
    "            pct = int(values_dict[top_key]/values_len*100)\n",
    "            message = f\"{pct}% of experts chose {converted_key}\"\n",
    "            df.loc[ix, \"pct\"] = pct\n",
    "            df.loc[ix, \"message\"] = message\n",
    "\n",
    "        df[\"game_id\"] = df[\"Game\"].apply(transform_game)\n",
    "        insert_expert_data(df)\n",
    "        return df[[\"game_id\", \"week\", \"Game\", \"Time\", \"pct\", \"message\"]]\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"get espn data, {e}\")\n",
    "\n",
    "def get_start_end():\n",
    "    today = datetime.now()\n",
    "    weekday = today.weekday()  # Monday is 0 and Sunday is 6\n",
    "\n",
    "    # Calculate the start date (Tuesday)\n",
    "    if weekday >= 1:  # If today is Tuesday or after\n",
    "        start_date = today - timedelta(days=(weekday - 1))\n",
    "    else:  # If today is before Tuesday\n",
    "        start_date = today - timedelta(days=(weekday + 6))\n",
    "\n",
    "    # Calculate the end date (Monday)\n",
    "    if weekday <= 0:  # If today is Monday\n",
    "        end_date = today\n",
    "    else:  # If today is after Monday\n",
    "        end_date = today + timedelta(days=(7 - weekday))\n",
    "    return start_date, end_date\n",
    "\n",
    "def main():\n",
    "    logger.info(\"STARTING data grab\")\n",
    "    start_date, end_date = get_start_end()\n",
    "    bovada_df = get_data(start_date, end_date)\n",
    "    matchup_df = generate_matchups(bovada_df)\n",
    "    expert_df = get_espn_expert_data()\n",
    "    expert_df.sort_values(\"pct\", ascending=False)\n",
    "    merged_df = pd.merge(matchup_df, expert_df, on=\"game_id\")\n",
    "    merged_df.drop(columns=[\"time\"], inplace=True)\n",
    "    merged_df[\"IngestTime\"] = datetime.now().strftime(\"%m/%d %H:%M\")\n",
    "    # merged_df = merged_df[[\"IngestTime\", \"week\", \"Game\", \"Time\", \"projected_winner\", \"ranking\", \"message\"]]\n",
    "    merged_df[\"ranking\"] = merged_df[\"ranking\"]+1\n",
    "    insert_merge_data(merged_df)\n",
    "    logger.info(\"COMPLETED data grab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adams\\AppData\\Local\\Temp\\ipykernel_38920\\86299954.py:292: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
      "C:\\Users\\adams\\AppData\\Local\\Temp\\ipykernel_38920\\86299954.py:294: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['date'].fillna(one_week_ago, inplace=True)\n",
      "C:\\Users\\adams\\AppData\\Local\\Temp\\ipykernel_38920\\86299954.py:324: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['DateTime'] = pd.to_datetime(df['date']+' '+df['time'])\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl-docker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
