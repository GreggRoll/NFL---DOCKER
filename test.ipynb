{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import hashlib\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import random\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "def setup_logger(name):\n",
    "    \"\"\"Set up a logger for a given module.\"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler('app.log')\n",
    "    formatter = logging.Formatter('%(asctime)s [%(levelname)s] - %(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "\n",
    "    # Add the handler to the logger\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(fh)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def insert_data_to_db(df, conn):\n",
    "    try:\n",
    "        df.to_sql('nfl_data', conn, if_exists='append', index=False)\n",
    "    except Exception as e:\n",
    "        logger.exception(\"insert_data_to_db\")\n",
    "\n",
    "def log_data_if_changed(current_df):\n",
    "    try:\n",
    "        with sqlite3.connect('data-log.db') as conn:\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # Initialize an empty list to collect DataFrames for concatenation\n",
    "            games_to_insert_list = []\n",
    "\n",
    "            # Iterate over each game in the current DataFrame\n",
    "            for index, game in current_df.iterrows():\n",
    "                game_id = game['game_id']\n",
    "\n",
    "                # Fetch the corresponding game data from the database by game_id\n",
    "                cursor.execute(\"SELECT * FROM nfl_data WHERE game_id = ?\", (game_id,))\n",
    "                db_game = cursor.fetchone()\n",
    "                columns = ['datetime', 'game_id', 'date', 'home_team', 'away_team', 'home_win', 'away_win', 'points']\n",
    "\n",
    "                if db_game:\n",
    "                    # Convert db_game to DataFrame for comparison\n",
    "                    db_game_df = pd.DataFrame([db_game], columns=columns)\n",
    "\n",
    "                    # Prepare current game data for comparison\n",
    "                    current_game_df = pd.DataFrame([game], columns=columns)\n",
    "                    current_game_df['datetime'] = datetime.now().isoformat()\n",
    "\n",
    "                    # Compare with current game data\n",
    "                    if not current_game_df.equals(db_game_df):\n",
    "                        # Add to the list for bulk insertion\n",
    "                        games_to_insert_list.append(current_game_df)\n",
    "                else:\n",
    "                    # If there is no entry for this game in the database, prepare for insertion\n",
    "                    game['datetime'] = datetime.now().isoformat()\n",
    "                    games_to_insert_list.append(pd.DataFrame([game], columns=columns))\n",
    "\n",
    "            # Concatenate all DataFrames in the list for bulk insertion\n",
    "            if games_to_insert_list:\n",
    "                games_to_insert = pd.concat(games_to_insert_list, ignore_index=True)\n",
    "                insert_data_to_db(games_to_insert, conn)\n",
    "    except Exception as e:\n",
    "        logger.exception(\"log_data_if_changed\")\n",
    "\n",
    "def concat_values(x, y, z=None):\n",
    "    if z:\n",
    "        return f\"{x} {y} {z}\"\n",
    "    return f\"{x} {y}\"\n",
    "\n",
    "def convert_to_int(value):\n",
    "    try:\n",
    "        if value == 'EVEN':\n",
    "            return 0\n",
    "        if value.startswith('+'):\n",
    "            return int(value[1:])\n",
    "        elif value.startswith('-'):\n",
    "            return int(value)\n",
    "        else:\n",
    "            return int(value)\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Convert to int error\")\n",
    "        return -1\n",
    "\n",
    "def generate_game_id(row):\n",
    "    try:\n",
    "        # Example: Use a combination of date, home team, and away team to generate a unique ID\n",
    "        identifier = f\"{row['date']}_{row['home_team']}_{row['away_team']}\"\n",
    "        return hashlib.md5(identifier.encode()).hexdigest()\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Generate Game error\")\n",
    "\n",
    "def get_data(start_date, end_date):\n",
    "    # Configure ChromeOptions for headless browsing\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")  # This line can be important in certain environments\n",
    "    options.set_capability('goog:loggingPrefs', {'browser': 'SEVERE'})\n",
    "    # Initialize the Chrome WebDriver with the specified options\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(\"https://www.bovada.lv/sports/football/nfl\")\n",
    "    # wait for the page to load\n",
    "    time.sleep(10)\n",
    "    driver.implicitly_wait(10)\n",
    "    # get the HTML source\n",
    "    html = driver.page_source\n",
    "    # create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    data = []\n",
    "    sections = soup.find_all(\"section\", {\"class\":\"coupon-content more-info\"})#soup.find_all(\"section\", {\"class\":\"coupon-content more-info\"})\n",
    "    for game in sections:\n",
    "        try:\n",
    "            item = str(game).split('>')\n",
    "            info = [x.split('<')[0].strip() for x in item if not x.startswith(\"<\")]\n",
    "            data.append(info)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"Home Spread\"] = df.apply(lambda row: concat_values(row[10], row[11]), axis=1)\n",
    "    df[\"Away Spread\"] = df.apply(lambda row: concat_values(row[12], row[13]), axis=1)\n",
    "    df[\"total_home\"] = df.apply(lambda row: concat_values(row[16], row[17], row[18]), axis=1)\n",
    "    df[\"total_away\"] = df.apply(lambda row: concat_values(row[19], row[20], row[21]), axis=1)\n",
    "\n",
    "    # List of column indices to keep\n",
    "    columns_to_keep = [0, 1, 2, 6, 7, 14, 15, 10, 12, 18, 21]\n",
    "\n",
    "    # Select the columns using iloc\n",
    "    df = df.iloc[:, columns_to_keep]\n",
    "\n",
    "\n",
    "    columns = [\"date\", \"time\", \"bets\", \"home_team\", \"away_team\", \"home_win\", \"away_win\", \"home_spread\", \"away_spread\", \"total_over\", \"total_under\"]\n",
    "    df.columns = columns\n",
    "\n",
    "    #remove plus from bets\n",
    "    df['bets'] = df['bets'].apply(lambda x: x[2:])\n",
    "\n",
    "    #date operations\n",
    "    #filter data for date\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')  # Adjust the format if needed\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')  # Adjust the format if needed\n",
    "        # Ensure the 'date' column in df is of type datetime.date\n",
    "\n",
    "\n",
    "    # Ensure the 'date' column in df is of type datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    one_week_ago = pd.Timestamp(datetime.today().date() - timedelta(weeks=1))\n",
    "    df['date'].fillna(one_week_ago, inplace=True)\n",
    "\n",
    "    df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "    #create day of the week column\n",
    "    df[\"day\"] = df['date'].dt.strftime('%A')\n",
    "    #set back to string\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Applying the conversion to the 'win_home' and \"Away Win\" columns\n",
    "    df['home_win'] = df['home_win'].apply(convert_to_int)\n",
    "    df[\"away_win\"] = df[\"away_win\"].apply(convert_to_int)\n",
    "    #ranking\n",
    "    home = df[[\"home_team\", 'home_win']].rename(columns={'home_team': 'team', 'home_win': 'odds'})\n",
    "    away = df[['away_team', \"away_win\"]].rename(columns={'away_team': 'team', \"away_win\": 'odds'})\n",
    "    combined = pd.concat([home, away]).sort_values('odds', ascending=False)\n",
    "    combined['index'] = combined.index\n",
    "    combined.index = range(0, 2*len(combined), 2)\n",
    "    df['points'] = None\n",
    "    # Iterating over the combined DataFrame to assign ranks\n",
    "    for i, x in combined.iterrows():\n",
    "        df.at[x['index'], 'points'] = (i-len(combined))/2+1\n",
    "    current_df = df.sort_values('points', ascending=False)\n",
    "    #add game id\n",
    "    current_df[\"game_id\"] = current_df.apply(generate_game_id, axis=1)\n",
    "    #change column order\n",
    "    current_df = current_df[['date', 'day', 'time', 'bets', 'home_team', 'away_team', 'points', 'home_win', 'away_win', 'home_spread', 'away_spread', 'total_over', 'total_under', 'game_id']]\n",
    "    log_data = current_df[['game_id', 'date', 'home_team', 'away_team', 'home_win', 'away_win', 'points']]\n",
    "    log_data_if_changed(log_data)\n",
    "    return current_df\n",
    "\n",
    "def generate_matchups(df):\n",
    "    # Ensure DateTime is properly formatted\n",
    "    df['DateTime'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Sort the DataFrame by DateTime to get matchups from soonest to latest\n",
    "    sorted_df = df.sort_values(by='DateTime')\n",
    "\n",
    "    # Prepare data for the DataTable\n",
    "    matchups_data = []\n",
    "\n",
    "    team_conversion_dict = {\n",
    "    \"Houston Texans\": \"HOU\",\n",
    "    \"New York Jets\": \"NYJ\",\n",
    "    \"Denver Broncos\": \"DEN\",\n",
    "    \"Baltimore Ravens\": \"BAL\",\n",
    "    \"Jacksonville Jaguars\": \"JAX\",\n",
    "    \"Philadelphia Eagles\": \"PHI\",\n",
    "    \"New Orleans Saints\": \"NO\",\n",
    "    \"Carolina Panthers\": \"CAR\",\n",
    "    \"Las Vegas Raiders\": \"LV\",\n",
    "    \"Cincinnati Bengals\": \"CIN\",\n",
    "    \"Miami Dolphins\": \"MIA\",\n",
    "    \"Buffalo Bills\": \"BUF\",\n",
    "    \"Indianapolis Colts\": \"IND\",\n",
    "    \"Minnesota Vikings\": \"MIN\",\n",
    "    \"Washington Commanders\": \"WSH\",\n",
    "    \"New York Giants\": \"NYG\",\n",
    "    \"Detroit Lions\": \"DET\",\n",
    "    \"Green Bay Packers\": \"GB\",\n",
    "    \"New England Patriots\": \"NE\",\n",
    "    \"Tennessee Titans\": \"TEN\",\n",
    "    \"Dallas Cowboys\": \"DAL\",\n",
    "    \"Atlanta Falcons\": \"ATL\",\n",
    "    \"Chicago Bears\": \"CHI\",\n",
    "    \"Arizona Cardinals\": \"ARI\",\n",
    "    \"Los Angeles Chargers\": \"LAC\",\n",
    "    \"Cleveland Browns\": \"CLE\",\n",
    "    \"Los Angeles Rams\": \"LAR\",\n",
    "    \"Seattle Seahawks\": \"SEA\",\n",
    "    \"Tampa Bay Buccaneers\": \"TB\",\n",
    "    \"Kansas City Chiefs\": \"KC\",\n",
    "    'San Francisco 49ers': \"SF\",\n",
    "    'Pittsburgh Steelers': \"PIT\"\n",
    "    }\n",
    "\n",
    "    for _, row in sorted_df.iterrows():\n",
    "        home_team = row['home_team']\n",
    "        away_team = row['away_team']\n",
    "        points = row['points']\n",
    "\n",
    "        # Determine the favored team\n",
    "        projected_winner = home_team if row['home_win'] < row['away_win'] else away_team\n",
    "\n",
    "        # Add row data\n",
    "        matchups_data.append({\n",
    "            \"game_id\": f\"{team_conversion_dict[home_team]}{team_conversion_dict[away_team]}\",\n",
    "            \"matchup\": f\"{home_team} vs {away_team}\",\n",
    "            \"time\": row['DateTime'].strftime('%H:%M %p'),\n",
    "            \"projected_winner\": projected_winner,\n",
    "            \"ranking\": points\n",
    "        })\n",
    "\n",
    "    return matchups_data\n",
    "\n",
    "def get_espn_expert_data():\n",
    "    # Function to transform the game string\n",
    "    def transform_game(game):\n",
    "        try:\n",
    "            teams = game.split(' at ')\n",
    "            return teams[0] + teams[1]\n",
    "        except:\n",
    "            teams = game.split(' VS ')\n",
    "            return teams[0] + teams[1]\n",
    "    try:\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--disable-extensions\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "        options.add_argument(\"--no-sandbox\")  # This line can be important in certain environments\n",
    "        options.set_capability('goog:loggingPrefs', {'browser': 'SEVERE'})\n",
    "        # Initialize the Chrome WebDriver with the specified options\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(\"https://www.espn.com/nfl/picks\")\n",
    "        #time.sleep(10)\n",
    "        driver.implicitly_wait(10)\n",
    "        # get the HTML source\n",
    "        html = driver.page_source\n",
    "        # create a BeautifulSoup object\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # close the driver\n",
    "        driver.quit()\n",
    "\n",
    "        week = soup.find('h1', class_='headline headline__h1 dib').get_text(strip=True).split('- ')[1]\n",
    "\n",
    "        # Extract game details\n",
    "        games = []\n",
    "        game_rows = soup.select('.Table--fixed-left .Table__TBODY .Table__TR')\n",
    "        for row in game_rows:\n",
    "            game_info_element = row.select_one('.wrap-competition a')\n",
    "            game_time_element = row.select_one('.competition-dates')\n",
    "            if game_info_element and game_time_element:\n",
    "                game_info = game_info_element.text\n",
    "                game_time = game_time_element.text\n",
    "                games.append((game_info, game_time))\n",
    "\n",
    "        # Extract expert names\n",
    "        experts = []\n",
    "        expert_headers = soup.select('.Table__Scroller .Table__THEAD .Table__TH')\n",
    "        for header in expert_headers:\n",
    "            expert_name_element = header.select_one('div')\n",
    "            if expert_name_element:\n",
    "                expert_name = expert_name_element.text.strip()\n",
    "                experts.append(expert_name)\n",
    "\n",
    "        # Extract picks\n",
    "        picks = []\n",
    "        pick_rows = soup.select('.Table__Scroller .Table__TBODY .Table__TR')\n",
    "        for row in pick_rows:\n",
    "            pick_row = []\n",
    "            pick_cells = row.select('.Table__TD')\n",
    "            for cell in pick_cells:\n",
    "                team_logo = cell.select_one('img')\n",
    "                if team_logo:\n",
    "                    # Extract the team abbreviation from the image URL\n",
    "                    team = team_logo['src'].split('/')[-1].split('.')[0]\n",
    "                else:\n",
    "                    team = None\n",
    "                pick_row.append(team)\n",
    "            picks.append(pick_row)\n",
    "\n",
    "        # Create DataFrame\n",
    "        data = {'Game': [game[0] for game in games], 'Time': [game[1] for game in games]}\n",
    "        for i, expert in enumerate(experts):\n",
    "            data[expert] = [pick[i] for pick in picks]\n",
    "\n",
    "        data['Game'].append(None)\n",
    "        data['Time'].append(None)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.dropna(subset=[\"Game\"], inplace=True)\n",
    "\n",
    "        df['week'] = week\n",
    "\n",
    "        convert_dict = {\n",
    "            \"min\": \"Vikings\", \"phi\": \"Eagles\", \"bal\": \"Ravens\", \"det\": \"Lions\", \"mia\": \"Dolphins\",\n",
    "            \"nyj\": \"Jets\", \"atl\": \"Falcons\", \"gb\": \"Packers\", \"hou\" : \"Texans\", \"lac\": \"Chargers\",\n",
    "            \"buf\": \"Bills\", \"den\": \"Broncos\", \"kc\": \"Chiefs\", \"chi\": \"Bears\", \"sf\": \"49ers\", \"pit\": \"Steelers\",\n",
    "            \"no\": \"Saints\", \"cin\": \"Bengals\", \"ne\": \"Patriots\", \"wsh\": \"Commanders\", \"ari\": \"Cardinals\", \n",
    "            \"lar\": \"Rams\"\n",
    "        }\n",
    "\n",
    "        for ix, row in df.iterrows():\n",
    "            values = row.to_list()[2:]\n",
    "            values = [value for value in values if value is not None]\n",
    "            values_len = len(values)\n",
    "            values_dict = {}\n",
    "            for value in values:\n",
    "                if value not in values_dict.keys():\n",
    "                    values_dict[value] = 1\n",
    "                else:\n",
    "                    values_dict[value] += 1\n",
    "            #sorting\n",
    "            values_dict = dict(sorted(values_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "            top_key = next(iter(values_dict))\n",
    "            if top_key in convert_dict:\n",
    "                converted_key = convert_dict[top_key]\n",
    "            else:\n",
    "                converted_key = top_key\n",
    "            pct = int(values_dict[top_key]/values_len*100)\n",
    "            message = f\"{pct}% of experts chose {converted_key}\"\n",
    "            df.loc[ix, \"pct\"] = pct\n",
    "            df.loc[ix, \"message\"] = message\n",
    "\n",
    "        df[\"game_id\"] = df[\"Game\"].apply(transform_game)\n",
    "        return df[[\"game_id\", \"week\", \"Game\", \"Time\", \"pct\", \"message\"]]\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"get espn data, {e}\")\n",
    "\n",
    "def get_start_end():\n",
    "    today = datetime.now()\n",
    "    weekday = today.weekday()  # Monday is 0 and Sunday is 6\n",
    "\n",
    "    # Calculate the start date (Tuesday)\n",
    "    if weekday >= 1:  # If today is Tuesday or after\n",
    "        start_date = today - timedelta(days=(weekday - 1))\n",
    "    else:  # If today is before Tuesday\n",
    "        start_date = today - timedelta(days=(weekday + 6))\n",
    "\n",
    "    # Calculate the end date (Monday)\n",
    "    if weekday <= 0:  # If today is Monday\n",
    "        end_date = today\n",
    "    else:  # If today is after Monday\n",
    "        end_date = today + timedelta(days=(7 - weekday))\n",
    "    return start_date, end_date\n",
    "\n",
    "logger = setup_logger(__name__)\n",
    "\n",
    "# Your script logic here\n",
    "start, end = get_start_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9168/3303875931.py:62: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
      "/tmp/ipykernel_9168/3303875931.py:64: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['date'].fillna(one_week_ago, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = get_start_end()\n",
    "\n",
    "# Configure ChromeOptions for headless browsing\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")  # This line can be important in certain environments\n",
    "options.set_capability('goog:loggingPrefs', {'browser': 'SEVERE'})\n",
    "# Initialize the Chrome WebDriver with the specified options\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://www.bovada.lv/sports/football/nfl\")\n",
    "# wait for the page to load\n",
    "time.sleep(10)\n",
    "driver.implicitly_wait(10)\n",
    "# get the HTML source\n",
    "html = driver.page_source\n",
    "# create a BeautifulSoup object\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "# close the driver\n",
    "driver.quit()\n",
    "\n",
    "data = []\n",
    "sections = soup.find_all(\"section\", {\"class\":\"coupon-content more-info\"})#soup.find_all(\"section\", {\"class\":\"coupon-content more-info\"})\n",
    "for game in sections:\n",
    "    try:\n",
    "        item = str(game).split('>')\n",
    "        info = [x.split('<')[0].strip() for x in item if not x.startswith(\"<\")]\n",
    "        data.append(info)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"Home Spread\"] = df.apply(lambda row: concat_values(row[10], row[11]), axis=1)\n",
    "df[\"Away Spread\"] = df.apply(lambda row: concat_values(row[12], row[13]), axis=1)\n",
    "df[\"total_home\"] = df.apply(lambda row: concat_values(row[16], row[17], row[18]), axis=1)\n",
    "df[\"total_away\"] = df.apply(lambda row: concat_values(row[19], row[20], row[21]), axis=1)\n",
    "\n",
    "# List of column indices to keep\n",
    "columns_to_keep = [0, 1, 2, 6, 7, 14, 15, 10, 12, 18, 21]\n",
    "\n",
    "# Select the columns using iloc\n",
    "df = df.iloc[:, columns_to_keep]\n",
    "\n",
    "\n",
    "columns = [\"date\", \"time\", \"bets\", \"home_team\", \"away_team\", \"home_win\", \"away_win\", \"home_spread\", \"away_spread\", \"total_over\", \"total_under\"]\n",
    "df.columns = columns\n",
    "\n",
    "#remove plus from bets\n",
    "df['bets'] = df['bets'].apply(lambda x: x[2:])\n",
    "\n",
    "#date operations\n",
    "#filter data for date\n",
    "if isinstance(start_date, str):\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d')  # Adjust the format if needed\n",
    "if isinstance(end_date, str):\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d')  # Adjust the format if needed\n",
    "    # Ensure the 'date' column in df is of type datetime.date\n",
    "\n",
    "\n",
    "# Ensure the 'date' column in df is of type datetime\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "one_week_ago = pd.Timestamp(datetime.today().date() - timedelta(weeks=1))\n",
    "df['date'].fillna(one_week_ago, inplace=True)\n",
    "\n",
    "df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "#create day of the week column\n",
    "df[\"day\"] = df['date'].dt.strftime('%A')\n",
    "#set back to string\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Applying the conversion to the 'win_home' and \"Away Win\" columns\n",
    "df['home_win'] = df['home_win'].apply(convert_to_int)\n",
    "df[\"away_win\"] = df[\"away_win\"].apply(convert_to_int)\n",
    "#ranking\n",
    "home = df[[\"home_team\", 'home_win']].rename(columns={'home_team': 'team', 'home_win': 'odds'})\n",
    "away = df[['away_team', \"away_win\"]].rename(columns={'away_team': 'team', \"away_win\": 'odds'})\n",
    "combined = pd.concat([home, away]).sort_values('odds', ascending=False)\n",
    "combined['index'] = combined.index\n",
    "combined.index = range(0, 2*len(combined), 2)\n",
    "df['points'] = None\n",
    "# Iterating over the combined DataFrame to assign ranks\n",
    "for i, x in combined.iterrows():\n",
    "    df.at[x['index'], 'points'] = (i-len(combined))/2+1\n",
    "current_df = df.sort_values('points', ascending=False)\n",
    "#add game id\n",
    "current_df[\"game_id\"] = current_df.apply(generate_game_id, axis=1)\n",
    "#change column order\n",
    "current_df = current_df[['date', 'day', 'time', 'bets', 'home_team', 'away_team', 'points', 'home_win', 'away_win', 'home_spread', 'away_spread', 'total_over', 'total_under', 'game_id']]\n",
    "log_data = current_df[['game_id', 'date', 'home_team', 'away_team', 'home_win', 'away_win', 'points']]\n",
    "log_data_if_changed(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9168/3655615320.py:170: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
      "/tmp/ipykernel_9168/3655615320.py:172: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['date'].fillna(one_week_ago, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "bovada_df = get_data(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>bets</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>points</th>\n",
       "      <th>home_win</th>\n",
       "      <th>away_win</th>\n",
       "      <th>home_spread</th>\n",
       "      <th>away_spread</th>\n",
       "      <th>total_over</th>\n",
       "      <th>total_under</th>\n",
       "      <th>game_id</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, day, time, bets, home_team, away_team, points, home_win, away_win, home_spread, away_spread, total_over, total_under, game_id, DateTime]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bovada_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_matchups(bovada_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ranking'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4812\\3048608941.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatchup_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_matchups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbovada_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ranking\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\adams\\anaconda3\\envs\\nfl-docker\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7185\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7186\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7187\u001b[0m             \u001b[1;31m# len(by) == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7189\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7191\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7192\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adams\\anaconda3\\envs\\nfl-docker\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ranking'"
     ]
    }
   ],
   "source": [
    "matchup_df = pd.DataFrame(generate_matchups(bovada_df)).sort_values(\"ranking\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "expert_df = get_espn_expert_data()\n",
    "expert_df.sort_values(\"pct\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = pd.merge(matchup_df, expert_df, on=\"game_id\")\n",
    "merged_df.drop(columns=[\"game_id\", \"time\", \"pct\", \"matchup\"], inplace=True)\n",
    "merged_df[\"IngestTime\"] = datetime.now().strftime(\"%m/%d %H:%M\")\n",
    "merged_df = merged_df[[\"IngestTime\", \"week\", \"Game\", \"Time\", \"projected_winner\", \"ranking\", \"message\"]]\n",
    "merged_df[\"ranking\"] = merged_df[\"ranking\"]+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl-docker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
